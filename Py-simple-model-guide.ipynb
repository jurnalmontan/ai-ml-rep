{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch # PyTorch library\n",
        "import torch.nn as nn # Neural network module\n",
        "import torch.optim as optim # Optimization algorithms\n",
        "import torch.nn.functional as F # Functional interface\n",
        "import torchvision # Computer vision library\n",
        "import torchvision.transforms as transforms # Image transformations\n",
        "import matplotlib.pyplot as plt # Plotting library"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations for the training and testing data sets and load CIFAR-10 dataset from torchvision datasets module with defined transformations\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform) # Download and load training data\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2) # Create data loader for training data\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform) # Download and load testing data\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2) # Create data loader for testing data"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 170M/170M [00:06<00:00, 25.6MB/s] \n"
        }
      ],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple Convolutional Neural Network (CNN) model using nn.Module class from torch.nn module \n",
        "class Net(nn.Module): # Define a simple CNN model\n",
        "    def __init__(self): # Initialize the model\n",
        "        super(Net, self).__init__() # Call the parent class constructor\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5) # First convolutional layer\n",
        "        self.pool = nn.MaxPool2d(2, 2) # Max pooling layer\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5) # Second convolutional layer\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # First fully connected layer\n",
        "        self.fc2 = nn.Linear(120, 84) # Second fully connected layer\n",
        "        self.fc3 = nn.Linear(84, 10) # Third fully connected layer\n",
        "\n",
        "    def forward(self, x): # Define the forward pass\n",
        "        x = self.pool(F.relu(self.conv1(x))) # Apply first convolutional layer, ReLU activation, and max pooling\n",
        "        x = self.pool(F.relu(self.conv2(x))) # Apply second convolutional layer, ReLU activation, and max pooling\n",
        "        x = x.view(-1, 16 * 5 * 5) # Flatten the tensor\n",
        "        x = F.relu(self.fc1(x)) # Apply first fully connected layer and ReLU activation\n",
        "        x = F.relu(self.fc2(x)) # Apply second fully connected layer and ReLU activation\n",
        "        x = self.fc3(x) # Apply third fully connected layer\n",
        "        return x # Return the output\n",
        "\n",
        "net = Net() # Instantiate the model "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a loss function and an optimizer for training the model \n",
        "criterion = nn.CrossEntropyLoss() # Cross-entropy loss function\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # Stochastic Gradient Descent (SGD) optimizer with learning rate and momentum\n"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model using the training data loader \n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0 # Initialize running loss\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data # Get inputs and labels from data loader\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad() \n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs) # Forward pass\n",
        "        loss = criterion(outputs, labels) # Compute loss\n",
        "        loss.backward() # Backward pass\n",
        "        optimizer.step() # Update weights\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item() # Accumulate loss\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}') # Print average loss\n",
        "            running_loss = 0.0 # Reset running loss\n",
        "\n",
        "print('Finished Training') "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[1,  2000] loss: 2.209\n[1,  4000] loss: 1.875\n[1,  6000] loss: 1.672\n[1,  8000] loss: 1.610\n[1, 10000] loss: 1.545\n[1, 12000] loss: 1.477\n[2,  2000] loss: 1.413\n[2,  4000] loss: 1.386\n[2,  6000] loss: 1.368\n[2,  8000] loss: 1.316\n[2, 10000] loss: 1.317\n[2, 12000] loss: 1.292\nFinished Training\n"
        }
      ],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data loader and calculate accuracy \n",
        "correct = 0 # Initialize correct predictions count\n",
        "total = 0 # Initialize total predictions count\n",
        "with torch.no_grad(): # Disable gradient calculation for evaluation\n",
        "    for data in testloader: # Iterate over test data\n",
        "        images, labels = data # Get images and labels\n",
        "        outputs = net(images) # Get model outputs\n",
        "        _, predicted = torch.max(outputs.data, 1) # Get predicted class\n",
        "        total += labels.size(0) # Update total count\n",
        "        correct += (predicted == labels).sum().item() # Update correct count\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total} %') # Print accuracy "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accuracy of the network on the 10000 test images: 54.64 %\n"
        }
      ],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model to a file using torch.save() function\n",
        "PATH = './cifar_net.pth' # Define the file path to save the model\n",
        "torch.save(net.state_dict(), PATH) # Save the model state dictionary to the file"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model from the file using torch.load() function \n",
        "net = Net() # Instantiate the model\n",
        "net.load_state_dict(torch.load(PATH)) # Load the model state dictionary from the file"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "<All keys matched successfully>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.10 - Pytorch and Tensorflow"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}