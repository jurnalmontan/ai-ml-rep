{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Project name: Customer Churn Prediction\n",
    "# Description: This project aims to predict customer churn using machine learning techniques.\n",
    "# Author: Razvan\n",
    "# Date: 2023-10-01\n",
    "# Version: 1.00\n",
    "# License: MIT License\n",
    "# Python Version: 3.8+\n",
    "# ML Framework: TensorFlow 2.x\n",
    "\n",
    "# Import TensorFlow libraries and load the dataset\n",
    "%pip install scikit-learn\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID  Tenure  MonthlyCharges  TotalCharges        Contract  \\\n",
      "0        1001       5            70.0         350.0  Month-to-month   \n",
      "1        1002      10            85.5         850.5        Two year   \n",
      "2        1003       3            55.3         165.9        One year   \n",
      "3        1004       8            90.0         720.0  Month-to-month   \n",
      "4        1005       2            65.2         130.4        One year   \n",
      "\n",
      "      PaymentMethod  Churn  \n",
      "0  Electronic check      1  \n",
      "1      Mailed check      0  \n",
      "2  Electronic check      1  \n",
      "3       Credit card      0  \n",
      "4  Electronic check      1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the customer churn dataset\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/jurnalmontan/ai-ml-rep/13becee3b8fed32def6dae2bfcb4a8c99dfd29a2/churn-dataset.csv') # Replace with your dataset path\n",
    "print(data.head()) # Display the first few rows of the dataset\n",
    "# Make sure to run the cell that imports pandas before running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target value counts: Churn\n",
      "1    3\n",
      "0    2\n",
      "Name: count, dtype: int64\n",
      "Unique values in target: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "data = data.dropna() # Drop rows with missing values\n",
    "\n",
    "# Fix target encoding: ensure 'Churn' is 0/1 (if originally Yes/No or similar)\n",
    "if data['Churn'].dtype == 'object':\n",
    "    y = (data['Churn'].str.lower() == 'yes').astype(int)\n",
    "else:\n",
    "    y = data['Churn']\n",
    "\n",
    "# Convert categorical variables to numerical using one-hot encoding (excluding 'Churn')\n",
    "X = data.drop('Churn', axis=1)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "print('Target value counts:', y.value_counts())\n",
    "print('Unique values in target:', np.unique(y))\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725ms/step - accuracy: 0.3333 - loss: 0.9717 - val_accuracy: 0.0000e+00 - val_loss: 1.2947\n",
      "Epoch 2/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725ms/step - accuracy: 0.3333 - loss: 0.9717 - val_accuracy: 0.0000e+00 - val_loss: 1.2947\n",
      "Epoch 2/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.3333 - loss: 0.9699 - val_accuracy: 0.0000e+00 - val_loss: 1.2896\n",
      "Epoch 3/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.3333 - loss: 0.9699 - val_accuracy: 0.0000e+00 - val_loss: 1.2896\n",
      "Epoch 3/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3333 - loss: 0.9680 - val_accuracy: 0.0000e+00 - val_loss: 1.2846\n",
      "Epoch 4/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3333 - loss: 0.9680 - val_accuracy: 0.0000e+00 - val_loss: 1.2846\n",
      "Epoch 4/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3333 - loss: 0.9662 - val_accuracy: 0.0000e+00 - val_loss: 1.2796\n",
      "Epoch 5/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3333 - loss: 0.9662 - val_accuracy: 0.0000e+00 - val_loss: 1.2796\n",
      "Epoch 5/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3333 - loss: 0.9643 - val_accuracy: 0.0000e+00 - val_loss: 1.2746\n",
      "Epoch 6/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3333 - loss: 0.9643 - val_accuracy: 0.0000e+00 - val_loss: 1.2746\n",
      "Epoch 6/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.3333 - loss: 0.9625 - val_accuracy: 0.0000e+00 - val_loss: 1.2696\n",
      "Epoch 7/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.3333 - loss: 0.9625 - val_accuracy: 0.0000e+00 - val_loss: 1.2696\n",
      "Epoch 7/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.3333 - loss: 0.9606 - val_accuracy: 0.0000e+00 - val_loss: 1.2647\n",
      "Epoch 8/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.3333 - loss: 0.9606 - val_accuracy: 0.0000e+00 - val_loss: 1.2647\n",
      "Epoch 8/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.3333 - loss: 0.9588 - val_accuracy: 0.0000e+00 - val_loss: 1.2597\n",
      "Epoch 9/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.3333 - loss: 0.9588 - val_accuracy: 0.0000e+00 - val_loss: 1.2597\n",
      "Epoch 9/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3333 - loss: 0.9570 - val_accuracy: 0.0000e+00 - val_loss: 1.2548\n",
      "Epoch 10/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3333 - loss: 0.9570 - val_accuracy: 0.0000e+00 - val_loss: 1.2548\n",
      "Epoch 10/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3333 - loss: 0.9552 - val_accuracy: 0.0000e+00 - val_loss: 1.2500\n",
      "Epoch 11/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3333 - loss: 0.9552 - val_accuracy: 0.0000e+00 - val_loss: 1.2500\n",
      "Epoch 11/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3333 - loss: 0.9533 - val_accuracy: 0.0000e+00 - val_loss: 1.2452\n",
      "Epoch 12/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3333 - loss: 0.9533 - val_accuracy: 0.0000e+00 - val_loss: 1.2452\n",
      "Epoch 12/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3333 - loss: 0.9515 - val_accuracy: 0.0000e+00 - val_loss: 1.2404\n",
      "Epoch 13/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3333 - loss: 0.9515 - val_accuracy: 0.0000e+00 - val_loss: 1.2404\n",
      "Epoch 13/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3333 - loss: 0.9497 - val_accuracy: 0.0000e+00 - val_loss: 1.2357\n",
      "Epoch 14/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3333 - loss: 0.9497 - val_accuracy: 0.0000e+00 - val_loss: 1.2357\n",
      "Epoch 14/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.3333 - loss: 0.9479 - val_accuracy: 0.0000e+00 - val_loss: 1.2310\n",
      "Epoch 15/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.3333 - loss: 0.9479 - val_accuracy: 0.0000e+00 - val_loss: 1.2310\n",
      "Epoch 15/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3333 - loss: 0.9461 - val_accuracy: 0.0000e+00 - val_loss: 1.2264\n",
      "Epoch 16/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3333 - loss: 0.9461 - val_accuracy: 0.0000e+00 - val_loss: 1.2264\n",
      "Epoch 16/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3333 - loss: 0.9443 - val_accuracy: 0.0000e+00 - val_loss: 1.2218\n",
      "Epoch 17/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3333 - loss: 0.9443 - val_accuracy: 0.0000e+00 - val_loss: 1.2218\n",
      "Epoch 17/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6667 - loss: 0.9425 - val_accuracy: 0.0000e+00 - val_loss: 1.2173\n",
      "Epoch 18/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6667 - loss: 0.9425 - val_accuracy: 0.0000e+00 - val_loss: 1.2173\n",
      "Epoch 18/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6667 - loss: 0.9407 - val_accuracy: 0.0000e+00 - val_loss: 1.2129\n",
      "Epoch 19/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6667 - loss: 0.9407 - val_accuracy: 0.0000e+00 - val_loss: 1.2129\n",
      "Epoch 19/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6667 - loss: 0.9389 - val_accuracy: 0.0000e+00 - val_loss: 1.2086\n",
      "Epoch 20/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6667 - loss: 0.9389 - val_accuracy: 0.0000e+00 - val_loss: 1.2086\n",
      "Epoch 20/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6667 - loss: 0.9371 - val_accuracy: 0.0000e+00 - val_loss: 1.2043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6667 - loss: 0.9371 - val_accuracy: 0.0000e+00 - val_loss: 1.2043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0000e+00 - loss: 0.7991\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0000e+00 - loss: 0.7991\n",
      "Simple NN Test Accuracy: 0.00%\n",
      "Simple NN Test Accuracy: 0.00%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "First 10 predictions: [0.55028784]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "First 10 predictions: [0.55028784]\n"
     ]
    }
   ],
   "source": [
    "# Ensure target arrays are float32 for TensorFlow\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "model = tf.keras.Sequential([ # Simple Neural Network\n",
    "    tf.keras.Input(shape=(X_train.shape[1],)), # Input layer\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid') # Output layer\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) # Compile the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2) # Train the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test) # Evaluate the model\n",
    "print(f'Simple NN Test Accuracy: {accuracy*100:.2f}%') # Print test accuracy\n",
    "\n",
    "# Print a few predictions to debug output\n",
    "preds = model.predict(X_test) # Get predictions\n",
    "print('First 10 predictions:', preds[:10].flatten()) # Print first 10 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train value counts: {1.0: 3, 0.0: 1}\n",
      "y_test value counts: {0.0: 1}\n",
      "Unique values in y_train: [0. 1.]\n",
      "Unique values in y_test: [0.]\n",
      "Logistic Regression Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Check target encoding and class balance before evaluation\n",
    "print('y_train value counts:', y_train.value_counts().to_dict())\n",
    "print('y_test value counts:', y_test.value_counts().to_dict())\n",
    "print('Unique values in y_train:', np.unique(y_train))\n",
    "print('Unique values in y_test:', np.unique(y_test))\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "lr_acc = lr.score(X_test, y_test)\n",
    "print(f\"Logistic Regression Test Accuracy: {lr_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphp7t9b3_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphp7t9b3_/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmphp7t9b3_'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 8), dtype=tf.float32, name='keras_tensor_14')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  133916285006272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  133916285009088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1759745438.461091    5223 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1759745438.461120    5223 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-10-06 10:10:38.461346: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmphp7t9b3_\n",
      "2025-10-06 10:10:38.461819: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-10-06 10:10:38.461832: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmphp7t9b3_\n",
      "2025-10-06 10:10:38.464564: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-10-06 10:10:38.479280: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmphp7t9b3_\n",
      "2025-10-06 10:10:38.485356: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 24013 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# Optimize for deployment\n",
    "# Optimize the model for deployment by considering techniques such as model pruning, quantization, or simplifying the model architecture without sacrificing too much accuracy. This step is crucial for ensuring the model can be deployed efficiently in a business environment.\n",
    "# Note: The dataset URL used in this example is for demonstration purposes. Replace it with the actual path to your dataset.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "with open('churn_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "# Prepare the model for deployment\n",
    "# Save the trained model in a format suitable for deployment, such as TensorFlow Lite or ONNX. This step ensures that the model can be easily integrated into production systems.\n",
    "# Note: The dataset URL used in this example is for demonstration purposes. Replace it with the actual path to your dataset.\n",
    "model.save('churn_model.keras')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py38_PT_TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
